{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps in a basic natural language processor:\n",
    "\n",
    "    1. Build a vocabulary - create unique id for each word\n",
    "\n",
    "    2. Feature Extraction - map frquency of each word in the vocab across the document in sparse matrices*\n",
    "\n",
    "    3. Bag of Words and TF-IDF\n",
    "\n",
    "    4. Stopwords removal\n",
    "    \n",
    "    5. Tagging\n",
    "\n",
    "*since each vector are mostly made up of 0s they are called sparse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "message    0\n",
       "length     0\n",
       "punct      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('smsspamcollection.tsv',sep='\\t')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction Code Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "\n",
    "#Fit the vectorizer to the data (build vocab, count words ........)\n",
    "    #count_vect.fit(X_train)\n",
    "#Individual Transform the original text to the data\n",
    "    #X_train_counts = count_vect.transform(X_train)\n",
    "\n",
    "#To do both fit and transform together in one line, we use the code fit_transform as shown:\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7069)\t1\n",
      "  (0, 4415)\t1\n",
      "  (0, 1736)\t1\n",
      "  (1, 5512)\t1\n",
      "  (1, 4270)\t1\n",
      "  (1, 5443)\t1\n",
      "  (1, 6330)\t2\n",
      "  (1, 5791)\t1\n",
      "  (1, 878)\t1\n",
      "  (1, 3008)\t1\n",
      "  (1, 2156)\t2\n",
      "  (1, 5468)\t1\n",
      "  (1, 935)\t1\n",
      "  (1, 2677)\t1\n",
      "  (1, 2566)\t1\n",
      "  (1, 5437)\t1\n",
      "  (1, 6247)\t1\n",
      "  (1, 3280)\t1\n",
      "  (1, 7048)\t1\n",
      "  (1, 957)\t1\n",
      "  (1, 6250)\t1\n",
      "  (1, 4470)\t1\n",
      "  (1, 938)\t1\n",
      "  (1, 5243)\t1\n",
      "  (1, 4513)\t1\n",
      "  :\t:\n",
      "  (3728, 6913)\t1\n",
      "  (3728, 2287)\t1\n",
      "  (3728, 3769)\t1\n",
      "  (3729, 1454)\t1\n",
      "  (3729, 5795)\t1\n",
      "  (3729, 3794)\t1\n",
      "  (3729, 3674)\t1\n",
      "  (3730, 5141)\t1\n",
      "  (3730, 3085)\t1\n",
      "  (3730, 2743)\t1\n",
      "  (3730, 4902)\t1\n",
      "  (3730, 5800)\t1\n",
      "  (3730, 5799)\t1\n",
      "  (3731, 6345)\t1\n",
      "  (3731, 4429)\t1\n",
      "  (3731, 5520)\t1\n",
      "  (3731, 3505)\t1\n",
      "  (3732, 3416)\t1\n",
      "  (3732, 3532)\t1\n",
      "  (3732, 2090)\t1\n",
      "  (3732, 5423)\t1\n",
      "  (3732, 3073)\t1\n",
      "  (3732, 6119)\t1\n",
      "  (3732, 5763)\t1\n",
      "  (3732, 4285)\t1\n",
      "(3733,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts)\n",
    "print(X_train.shape)\n",
    "\n",
    "#the sparse matrix in X_train_counts has 3733x7082 which maches with X train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TF-IDF Transformer with Count Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_trans = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_trans.fit_transform(X_train_counts) # Here we use X_train_counts since we are doing on TFIDF Transformation\n",
    "\n",
    "# For combined TF-IDF + Count Vectorization, we use TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "#Here we only pass X_train since Vectorizer does both Count Vectorization and TFIDF\n",
    "X_train_tfidf =vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC()\n",
    "\n",
    "clf.fit(X_train_tfidf,y_train)\n",
    "\n",
    "#Creating a pipeline to combine the steps in one shot using pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('tfidf',TfidfVectorizer()),('clf',LinearSVC())])\n",
    "text_clf.fit(X_train,y_train) # Can be fit directly to the pipeline object\n",
    "predictions = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1586    7]\n",
      " [  12  234]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1593\n",
      "        spam       0.97      0.95      0.96       246\n",
      "\n",
      "    accuracy                           0.99      1839\n",
      "   macro avg       0.98      0.97      0.98      1839\n",
      "weighted avg       0.99      0.99      0.99      1839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performance for SVC Pipeline\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print (confusion_matrix(y_test,predictions))\n",
    "print (classification_report(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d022b30961834b78ff4306c29056cec93bdf74ce7abe517b039f3845ba48d0a9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('nlp_course': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
